# -*- coding: utf-8 -*-
"""
Created on Tue Oct 10 14:35:48 2023

@author: Mieszko Ferens

Script to evaluate the bias of bit strings generated in a PU-QKD system, as
well, as the accuracy of training set generated by an attacker.
"""

import numpy as np
import pypuf.attack
from pypuf.simulation import XORArbiterPUF

class ChallengeResponseSet():
    def __init__(self, n, challenges, responses):
        self.challenge_length = n
        self.challenges = challenges
        self.responses = np.expand_dims(
            np.expand_dims(responses,axis=1),axis=1)

# Simulation parameters
seed = 0
n = 64
puf = XORArbiterPUF(n, 1, seed)
challenges = 2 * np.random.randint(0, 2, (1000000, n), dtype=np.int8) - 1
responses = puf.eval(challenges)

# Emulated quantum RNG
rng = np.random.default_rng(seed=seed)

# Iteration counter
batch_size = 50000
n_batches = int(len(responses)/batch_size)

# Test samples for modeling attack
test_x = challenges[n_batches-1*batch_size:(n_batches)*batch_size]
test_y = 0.5 - 0.5*responses[n_batches-1*batch_size:(n_batches)*batch_size]
test_y = test_y.reshape(len(test_y), 1)

# Metrics
accuracies = []
trainset_accuracies = []
trainset_bias = []

batch = 0
## Initial model

bits = rng.integers(low=0, high=2, size=batch_size)

encoded = np.logical_xor(
    bits > 0,
    responses[batch*batch_size:(batch+1)*batch_size].flatten() > 0)

r_guess = np.random.rand(batch_size) < 0.7

# Evaluate training set (for information purposes)
trainset_bias.append(np.count_nonzero(r_guess)/len(r_guess))
print("Training set bias is: " + str(trainset_bias[batch]))
trainset_accuracies.append(
    np.count_nonzero(
        ((r_guess*2)-1).flatten() ==
        responses[batch*batch_size:(batch+1)*batch_size].flatten())/batch_size)
print("Training set accuracy is: " + str(trainset_accuracies[batch]))

train_crps = ChallengeResponseSet(
    n, challenges[batch*batch_size:(batch+1)*batch_size],
    np.array((r_guess*2) - 1, dtype=np.float64))

network = [8, 16, 8]
model = pypuf.attack.MLPAttack2021(
    train_crps, seed=seed, net=network, epochs=30, lr=.001,
    bs=1000, early_stop=.08)

model.fit()

pred_y = model._model.eval(test_x)
pred_y = pred_y.reshape(len(pred_y), 1)
accuracies.append(np.count_nonzero(((pred_y<0.5) + test_y)-1)/len(test_y))
print("Tested model accuracy is: " + str(accuracies[batch]))

## Subsequent model improvement
batch += 1
while(batch < n_batches - 10):
    
    bits = np.append(bits, rng.integers(low=0, high=2, size=batch_size))
    
    encoded = np.append(encoded, np.logical_xor(
        bits[batch*batch_size:(batch+1)*batch_size] > 0,
        responses[batch*batch_size:(batch+1)*batch_size].flatten() > 0))
    
    guess = model._model.eval(challenges[:(batch+1)*batch_size])
    
    r_guess = np.random.rand(batch_size*(batch+1)) < 0.7
    
    idx = np.where(r_guess == (guess.flatten() == 1))[0]
    
    # Evaluate training set (for information purposes)
    trainset_bias.append(np.count_nonzero(guess[idx] == 1)/len(idx))
    print("Training set bias is: " + str(trainset_bias[batch]))
    trainset_accuracies.append(
        np.count_nonzero(
            guess[idx].flatten() == responses[idx].flatten())/len(idx))
    print("Training set accuracy is: " + str(trainset_accuracies[batch]))
    
    train_crps = ChallengeResponseSet(
        n, challenges[idx], np.array(guess[idx], dtype=np.float64))
    
    network = [8, 16, 8]
    model = pypuf.attack.MLPAttack2021(
        train_crps, seed=seed, net=network, epochs=30, lr=.001,
        bs=1000, early_stop=.08)
    
    model.fit()
    
    pred_y = model._model.eval(test_x)
    pred_y = pred_y.reshape(len(pred_y), 1)
    accuracies.append(np.count_nonzero(((pred_y<0.5) + test_y)-1)/len(test_y))
    print("Tested model accuracy is: " + str(accuracies[batch]))
    
    batch += 1
    
    